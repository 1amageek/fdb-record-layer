# OnlineIndexScrubber: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨­è¨ˆ

## ç›®æ¬¡

1. [ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—](#ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—)
2. [æ¦‚è¦](#æ¦‚è¦)
3. [ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£](#ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£)
4. [ScrubberResultè¨­è¨ˆ](#scrubberresultè¨­è¨ˆ)
5. [swift-metricsçµ±åˆ](#swift-metricsçµ±åˆ)
6. [RangeSetçµ±åˆ](#rangesetçµ±åˆ)
7. [ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æˆ¦ç•¥](#ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æˆ¦ç•¥)
8. [ãƒ­ã‚°æˆ¦ç•¥](#ãƒ­ã‚°æˆ¦ç•¥)
9. [ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è€ƒæ…®äº‹é …](#ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è€ƒæ…®äº‹é …)
10. [é‹ç”¨ã‚¬ã‚¤ãƒ‰](#é‹ç”¨ã‚¬ã‚¤ãƒ‰)
11. [å®Ÿè£…ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹](#å®Ÿè£…ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹)
12. [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)

---

## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### ä¾å­˜é–¢ä¿‚ã®è¿½åŠ 

`Package.swift`ã«ä»¥ä¸‹ã®ä¾å­˜é–¢ä¿‚ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ï¼š

```swift
// swift-tools-version: 6.0
import PackageDescription

let package = Package(
    name: "fdb-record-layer",
    platforms: [
        .macOS(.v15),
    ],
    dependencies: [
        .package(url: "https://github.com/apple/swift-log.git", from: "1.6.4"),
        .package(url: "https://github.com/apple/swift-metrics.git", from: "2.5.0"),
        .package(url: "https://github.com/MrLotU/SwiftPrometheus.git", from: "1.0.0"),
        // ... other dependencies
    ],
    targets: [
        .target(
            name: "FDBRecordLayer",
            dependencies: [
                .product(name: "Logging", package: "swift-log"),
                .product(name: "Metrics", package: "swift-metrics"),
                .product(name: "SwiftPrometheus", package: "SwiftPrometheus"),
                // ... other dependencies
            ]
        )
    ]
)
```

### MetricsSystemã®ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—

ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ™‚ã«ã€**ä¸€åº¦ã ã‘**`MetricsSystem.bootstrap()`ã‚’å‘¼ã³å‡ºã—ã¦ãã ã•ã„ï¼š

```swift
import Metrics
import SwiftPrometheus

@main
struct MyApplication {
    static func main() {
        // âš ï¸ é‡è¦: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ™‚ã«ä¸€åº¦ã ã‘å‘¼ã³å‡ºã™
        // è¤‡æ•°å›å‘¼ã³å‡ºã™ã¨ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã—ã¾ã™
        MetricsSystem.bootstrap(PrometheusMetrics())

        // ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯
        Task {
            try await startApplication()
        }

        // ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å…¬é–‹
        startMetricsServer()
    }
}
```

### ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®å…¬é–‹

PrometheusãŒãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã§ãã‚‹ã‚ˆã†ã«ã€HTTPã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å…¬é–‹ã—ã¾ã™ï¼š

```swift
import Vapor
import SwiftPrometheus

func startMetricsServer() {
    let app = Application()
    defer { app.shutdown() }

    // GET /metrics ã§Prometheuså½¢å¼ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¿”ã™
    app.get("metrics") { req -> String in
        let prometheus = MetricsSystem.factory as! PrometheusMetrics
        return prometheus.collect()
    }

    try app.run()
}
```

**ã¾ãŸã¯ã€Vaporãªã—ã§Swift NIOã‚’ä½¿ã†å ´åˆ**:

```swift
import NIO
import NIOHTTP1

func startMetricsServer() {
    let group = MultiThreadedEventLoopGroup(numberOfThreads: 1)
    defer { try? group.syncShutdownGracefully() }

    let bootstrap = ServerBootstrap(group: group)
        .serverChannelOption(ChannelOptions.backlog, value: 256)
        .childChannelInitializer { channel in
            channel.pipeline.addHandlers([
                HTTPServerCodec(),
                MetricsHandler()
            ])
        }

    let channel = try! bootstrap.bind(host: "0.0.0.0", port: 9090).wait()
    print("Metrics server started on http://0.0.0.0:9090/metrics")
    try! channel.closeFuture.wait()
}
```

---

## æ¦‚è¦

### è¨­è¨ˆåŸå‰‡

OnlineIndexScrubberã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨­è¨ˆã¯ã€ä»¥ä¸‹ã®åŸå‰‡ã«åŸºã¥ã„ã¦ã„ã¾ã™ï¼š

1. **è²¬ä»»ã®åˆ†é›¢**: å³åº§ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼ˆScrubberResultï¼‰ã¨è©³ç´°ãªé‹ç”¨ç›£è¦–ï¼ˆswift-metricsï¼‰ã‚’åˆ†é›¢
2. **é‹ç”¨å„ªå…ˆ**: ãƒ­ã‚°ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã§ã€Œä½•ãŒèµ·ããŸã‹ã€ã€Œã©ã†å¯¾å‡¦ã™ã¹ãã‹ã€ã‚’æ˜ç¢ºã«ä¼ãˆã‚‹
3. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**: ãƒ¡ãƒ¢ãƒªã¨I/Oã‚’åŠ¹ç‡çš„ã«ä½¿ç”¨ï¼ˆãƒãƒƒãƒè¨˜éŒ²ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰
4. **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£**: PIIï¼ˆå€‹äººè­˜åˆ¥æƒ…å ±ï¼‰ã‚’å«ã‚€ã‚­ãƒ¼ã‚’ãƒ­ã‚°ã«å‡ºåŠ›ã—ãªã„
5. **ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•**: swift-metricsã¯Sendableã§ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ã€actorã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§å®‰å…¨ã«ä½¿ç”¨å¯èƒ½
6. **ç°¡æ½”æ€§**: å¾Œæ–¹äº’æ›æ€§ã‚’è€ƒæ…®ã›ãšã€æœ€å°é™ã®å®Ÿè£…ã§æœ€å¤§ã®ä¾¡å€¤ã‚’æä¾›

### ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ã®ç›®æ¨™

- âœ… **é–‹ç™ºè€…**: `result.isHealthy`ã§å³åº§ã«å¥å…¨æ€§ã‚’åˆ¤å®š
- âœ… **é‹ç”¨è€…**: Grafanaãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§è©³ç´°ã‚’åˆ†æ
- âœ… **SRE**: ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«ã§ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆæ¤œçŸ¥
- âœ… **ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ã‚¿ãƒ¼**: ãƒ­ã‚°ã§æ ¹æœ¬åŸå› ã‚’ç‰¹å®š

---

## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### å…¨ä½“æ§‹æˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   OnlineIndexScrubber (actor)                â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚
â”‚  â”‚ scrubIndex() â”‚                                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â”‚         â”‚                                                    â”‚
â”‚         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚         â”‚                                      â”‚            â”‚
â”‚         v                                      v            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Phase 1         â”‚                  â”‚ Phase 2         â”‚  â”‚
â”‚  â”‚ (Index Entries) â”‚                  â”‚ (Records)       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â”‚                                     â”‚           â”‚
â”‚           v                                     v           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚        Metrics Recording Layer                      â”‚    â”‚
â”‚  â”‚  - scanProgressCounter (batched)                    â”‚    â”‚
â”‚  â”‚  - issuesCounter                                    â”‚    â”‚
â”‚  â”‚  - skipCounter                                      â”‚    â”‚
â”‚  â”‚  - retryCounter                                     â”‚    â”‚
â”‚  â”‚  - progressGauge (from RangeSet)                    â”‚    â”‚
â”‚  â”‚  - scanDuration                                     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                   â”‚                                         â”‚
â”‚                   v                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚        Logging Layer (with sampling)                â”‚    â”‚
â”‚  â”‚  - logger.info (progress)                           â”‚    â”‚
â”‚  â”‚  - logger.warning (sampled: 1/100)                  â”‚    â”‚
â”‚  â”‚  - logger.error (fatal errors)                      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                   â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                       â”‚
        v                       v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ScrubberResultâ”‚        â”‚ swift-metrics   â”‚
â”‚(æœ€å°é™)      â”‚        â”‚ Backend         â”‚
â”‚- isHealthy   â”‚        â”‚ (Prometheus)    â”‚
â”‚- summary     â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
       â”‚                         â”‚
       v                         v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚å‘¼ã³å‡ºã—å´    â”‚        â”‚ Grafana         â”‚
â”‚(å³åº§åˆ¤å®š)    â”‚        â”‚ Dashboard       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼

```
[ã‚¹ã‚­ãƒ£ãƒ³é–‹å§‹]
    â”‚
    â”œâ”€â†’ [RangeSet] é€²æ—ç‡ã‚’å–å¾— â†’ progressGauge.record(0.0)
    â”‚
    â”œâ”€â†’ [ãƒãƒƒãƒå‡¦ç†]
    â”‚     â”œâ”€ ã‚¨ãƒ³ãƒˆãƒªã‚’ã‚¹ã‚­ãƒ£ãƒ³ï¼ˆä¾‹: 1000ä»¶ï¼‰
    â”‚     â”œâ”€ ãƒãƒƒãƒçµ‚äº†æ™‚ã«ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
    â”‚     â”‚   â””â”€â†’ scanProgressCounter.increment(by: 1000)
    â”‚     â”‚
    â”‚     â”œâ”€ Tuple decodeå¤±æ•—ï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: 1/100ã§ãƒ­ã‚°ï¼‰
    â”‚     â”‚   â”œâ”€â†’ [ãƒ¡ãƒˆãƒªã‚¯ã‚¹] skipCounter++ (reason=tuple_decode)
    â”‚     â”‚   â”œâ”€â†’ [ãƒ­ã‚°] logger.warning("Tuple decode failed") â€»ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    â”‚     â”‚   â””â”€â†’ continue (ã‚¹ã‚­ãƒƒãƒ—)
    â”‚     â”‚
    â”‚     â”œâ”€ Dangling entryæ¤œå‡º
    â”‚     â”‚   â”œâ”€â†’ [ãƒ¡ãƒˆãƒªã‚¯ã‚¹] issuesCounter++ (type=dangling_entry)
    â”‚     â”‚   â”œâ”€â†’ [ãƒ­ã‚°] logger.warning("Dangling entry")
    â”‚     â”‚   â””â”€â†’ allowRepair=true ãªã‚‰å‰Šé™¤
    â”‚     â”‚
    â”‚     â””â”€ Deserializationå¤±æ•—ï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰
    â”‚         â”œâ”€â†’ [ãƒ¡ãƒˆãƒªã‚¯ã‚¹] skipCounter++ (reason=deserialization)
    â”‚         â”œâ”€â†’ [ãƒ­ã‚°] logger.warning("Deserialization failed") â€»ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    â”‚         â””â”€â†’ continue (ã‚¹ã‚­ãƒƒãƒ—)
    â”‚
    â”œâ”€â†’ [ãƒªãƒˆãƒ©ã‚¤å‡¦ç†]
    â”‚     â””â”€ å¤±æ•—æ™‚
    â”‚         â”œâ”€â†’ [ãƒ¡ãƒˆãƒªã‚¯ã‚¹] retryCounter++ (error_code=1007)
    â”‚         â”œâ”€â†’ [ãƒ­ã‚°] logger.warning("Retry #{n}")
    â”‚         â””â”€â†’ exponential backoff
    â”‚
    â”œâ”€â†’ [RangeSetæ›´æ–°] ãƒãƒƒãƒå®Œäº†ç¯„å›²ã‚’è¨˜éŒ²
    â”‚     â””â”€â†’ progressGauge.record(0.25)  // 25%å®Œäº†
    â”‚
    â””â”€â†’ [å®Œäº†]
          â”œâ”€â†’ [ãƒ¡ãƒˆãƒªã‚¯ã‚¹] scanDuration.record(elapsed)
          â”œâ”€â†’ [RangeSet] é€²æ—ç‡ 100%
          â”œâ”€â†’ [ãƒ­ã‚°] logger.info("Completed")
          â””â”€â†’ [æˆ»ã‚Šå€¤] ScrubberResult
```

---

## ScrubberResultè¨­è¨ˆ

### è¨­è¨ˆæ–¹é‡

**æœ€å°é™ã®æƒ…å ±ã®ã¿ã‚’è¿”ã™**: è©³ç´°ãªçµ±è¨ˆæƒ…å ±ã¯swift-metricsã«å§”è­²ã—ã€APIå‘¼ã³å‡ºã—å´ãŒå³åº§ã«åˆ¤å®šã§ãã‚‹æƒ…å ±ã®ã¿ã«çµã‚‹ã€‚

### ãƒ‡ãƒ¼ã‚¿æ§‹é€ 

```swift
/// ã‚¹ã‚¯ãƒ©ãƒãƒ¼å®Ÿè¡Œçµæœï¼ˆæœ€å°é™ï¼‰
///
/// è©³ç´°ãªçµ±è¨ˆæƒ…å ±ã¯ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚·ã‚¹ãƒ†ãƒ ã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚
/// - Prometheus Query: `fdb_scrubber_*{index="your_index_name"}`
public struct ScrubberResult: Sendable {
    /// å¥å…¨æ€§ãƒ•ãƒ©ã‚°
    ///
    /// `true` ã®å ´åˆã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å•é¡Œã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚
    /// `false` ã®å ´åˆã€Issue ãŒæ¤œå‡ºã•ã‚ŒãŸã‹ã€ã‚¹ã‚­ãƒ£ãƒ³ãŒé€”ä¸­çµ‚äº†ã—ã¾ã—ãŸã€‚
    public let isHealthy: Bool

    /// æ­£å¸¸å®Œäº†ãƒ•ãƒ©ã‚°
    ///
    /// `true` ã®å ´åˆã€Phase 1 ã¨ Phase 2 ãŒå®Œå…¨ã«å®Ÿè¡Œã•ã‚Œã¾ã—ãŸã€‚
    /// `false` ã®å ´åˆã€ã‚¨ãƒ©ãƒ¼ã«ã‚ˆã‚Šé€”ä¸­çµ‚äº†ã—ã¾ã—ãŸã€‚
    public let completedSuccessfully: Bool

    /// å®Ÿè¡Œã‚µãƒãƒª
    public let summary: ScrubberSummary

    /// é€”ä¸­çµ‚äº†ã®ç†ç”±ï¼ˆæ­£å¸¸å®Œäº†æ™‚ã¯ nilï¼‰
    public let terminationReason: String?
}

/// ã‚¹ã‚¯ãƒ©ãƒãƒ¼å®Ÿè¡Œã®ã‚µãƒãƒªæƒ…å ±
public struct ScrubberSummary: Sendable {
    /// å®Ÿè¡Œæ™‚é–“ï¼ˆç§’ï¼‰
    public let timeElapsed: TimeInterval

    /// ã‚¹ã‚­ãƒ£ãƒ³ã—ãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚¨ãƒ³ãƒˆãƒªæ•°
    public let entriesScanned: Int

    /// ã‚¹ã‚­ãƒ£ãƒ³ã—ãŸãƒ¬ã‚³ãƒ¼ãƒ‰æ•°
    public let recordsScanned: Int

    /// æ¤œå‡ºã•ã‚ŒãŸ Issue ã®ç·æ•°
    ///
    /// - Dangling entries
    /// - Missing entries
    public let issuesDetected: Int

    /// ä¿®å¾©ã•ã‚ŒãŸ Issue ã®æ•°
    ///
    /// `configuration.allowRepair=true` ã®å ´åˆã®ã¿ 0 ä»¥å¤–ã«ãªã‚Šã¾ã™ã€‚
    public let issuesRepaired: Int

    /// ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åï¼ˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¯ã‚¨ãƒªç”¨ã®ãƒ’ãƒ³ãƒˆï¼‰
    public let indexName: String

    /// ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚·ã‚¹ãƒ†ãƒ ã¸ã®ãƒ’ãƒ³ãƒˆ
    ///
    /// è©³ç´°ãªçµ±è¨ˆæƒ…å ±ã‚’ç¢ºèªã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚
    public var metricsHint: String {
        """
        For detailed statistics, query the metrics system:

        Prometheus Examples:
        - fdb_scrubber_entries_scanned_total{index="\(indexName)"}
        - fdb_scrubber_issues_total{index="\(indexName)",type="dangling_entry"}
        - fdb_scrubber_skipped_total{index="\(indexName)",reason="deserialization_failure"}
        - fdb_scrubber_progress_ratio{index="\(indexName)"}

        Grafana Dashboard: http://grafana:3000/d/fdb-scrubber
        """
    }
}
```

### ä½¿ç”¨ä¾‹

```swift
// ã‚¹ã‚¯ãƒ©ãƒãƒ¼ã®å®Ÿè¡Œ
let result = try await scrubber.scrubIndex()

// âœ… ã‚·ãƒ³ãƒ—ãƒ«ãªå¥å…¨æ€§ãƒã‚§ãƒƒã‚¯
if result.isHealthy {
    print("âœ… Index is healthy")
} else {
    print("âš ï¸  Issues detected: \(result.summary.issuesDetected)")
    print("ğŸ“Š For details: \(result.summary.metricsHint)")
}

// âœ… ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ†ã‚£ãƒƒã‚¯ãªå‡¦ç†
if !result.completedSuccessfully {
    if let reason = result.terminationReason {
        logger.error("Scrubber failed", metadata: ["reason": "\(reason)"])
        // ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡
        alerting.send(.scrubberFailed(index: indexName, reason: reason))
    }
}

// âœ… çµ±è¨ˆæƒ…å ±ã®ç¢ºèª
print("""
Scrubber Summary:
  Time: \(result.summary.timeElapsed)s
  Entries: \(result.summary.entriesScanned)
  Records: \(result.summary.recordsScanned)
  Issues: \(result.summary.issuesDetected) detected, \(result.summary.issuesRepaired) repaired
""")
```

---

## swift-metricsçµ±åˆ

### ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ç¨®é¡ã¨ç‰¹æ€§

swift-metricsã¯**ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•**ã§**Sendableãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«æº–æ‹ **ã—ã¦ã„ã‚‹ãŸã‚ã€actorã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚„ä¸¦è¡Œã‚¿ã‚¹ã‚¯ã‹ã‚‰å®‰å…¨ã«ä½¿ç”¨ã§ãã¾ã™ã€‚

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹å | å‹ | èª¬æ˜ | ãƒ©ãƒ™ãƒ« | ãƒãƒƒãƒè¨˜éŒ² |
|------------|---|------|--------|-----------|
| `fdb_scrubber_entries_scanned_total` | Counter | ã‚¹ã‚­ãƒ£ãƒ³ã—ãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚¨ãƒ³ãƒˆãƒªã®ç·æ•° | index, index_type | âœ… æ¨å¥¨ |
| `fdb_scrubber_issues_total` | Counter | æ¤œå‡ºã•ã‚ŒãŸ Issue ã®ç·æ•° | index, type, phase | âŒ å³åº§ |
| `fdb_scrubber_skipped_total` | Counter | ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸã‚¨ãƒ³ãƒˆãƒªã®ç·æ•° | index, reason, phase | âœ… æ¨å¥¨ |
| `fdb_scrubber_retries_total` | Counter | ãƒªãƒˆãƒ©ã‚¤ã®ç·æ•° | index, error_code, phase, operation | âŒ å³åº§ |
| `fdb_scrubber_progress_ratio` | Gauge | ã‚¹ã‚­ãƒ£ãƒ³é€²æ—ç‡ï¼ˆ0.0ã€œ1.0ï¼‰ | index, phase | âŒ å³åº§ |
| `fdb_scrubber_scan_duration_seconds` | Timer | ã‚¹ã‚­ãƒ£ãƒ³å®Ÿè¡Œæ™‚é–“ï¼ˆç§’ï¼‰ | index, index_type | âŒ çµ‚äº†æ™‚ |
| `fdb_scrubber_batch_size` | Recorder | ãƒãƒƒãƒã‚µã‚¤ã‚ºã®åˆ†å¸ƒ | index, phase | âŒ ãƒãƒƒãƒæ¯ |

### ãƒ¡ãƒˆãƒªã‚¯ã‚¹å‹ã®è©³ç´°

#### Counter
- **ç”¨é€”**: å˜èª¿å¢—åŠ ã™ã‚‹å€¤ï¼ˆãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã€ã‚¨ãƒ©ãƒ¼æ•°ãªã©ï¼‰
- **ãƒ¡ã‚½ãƒƒãƒ‰**: `increment(by: Int = 1)`
- **ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•**: âœ… ã¯ã„ï¼ˆè¤‡æ•°ã®ã‚¿ã‚¹ã‚¯ã‹ã‚‰å‘¼ã³å‡ºã—å¯èƒ½ï¼‰

```swift
let counter = Counter(label: "http_requests_total", dimensions: [("path", "/")])
counter.increment()
counter.increment(by: 100)
```

#### Timer
- **ç”¨é€”**: å‡¦ç†æ™‚é–“ã®æ¸¬å®š
- **ãƒ¡ã‚½ãƒƒãƒ‰**: `recordNanoseconds(Int64)`, `recordSeconds(Double)`
- **é›†è¨ˆ**: min, max, quantilesï¼ˆãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãŒå¯¾å¿œã—ã¦ã„ã‚‹å ´åˆï¼‰

```swift
let timer = Timer(label: "request_duration_seconds")
timer.recordNanoseconds(100_000_000)  // 100ms
timer.recordSeconds(0.5)  // 500ms
```

#### Recorder
- **ç”¨é€”**: å€¤ã®åˆ†å¸ƒæ¸¬å®šï¼ˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚µã‚¤ã‚ºã€ã‚­ãƒ¥ãƒ¼ã‚µã‚¤ã‚ºãªã©ï¼‰
- **ãƒ¡ã‚½ãƒƒãƒ‰**: `record(Int64)` ã¾ãŸã¯ `record(Double)`
- **é›†è¨ˆ**: count, sum, min, max, quantilesï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: `aggregate: true`ï¼‰

```swift
let recorder = Recorder(label: "response_size_bytes")
recorder.record(1024)
```

#### Gauge
- **ç”¨é€”**: ä¸Šä¸‹ã™ã‚‹å€¤ï¼ˆæ¸©åº¦ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãªã©ï¼‰
- **å®Ÿè£…**: `Recorder(aggregate: false)`ã¨ã—ã¦å®Ÿè£…
- **ç‰¹å¾´**: æœ€æ–°ã®å€¤ã®ã¿ã‚’ä¿æŒï¼ˆé›†è¨ˆã—ãªã„ï¼‰

```swift
let gauge = Gauge(label: "current_temperature_celsius")
gauge.record(25.5)
```

### ãƒ©ãƒ™ãƒ«ï¼ˆDimensionsï¼‰ã®ä½¿ã„æ–¹

ãƒ©ãƒ™ãƒ«ã¯`[(String, String)]`ã®é…åˆ—ã§æŒ‡å®šã—ã¾ã™ï¼š

```swift
// ãƒ©ãƒ™ãƒ«ä»˜ãCounter
let counter = Counter(
    label: "fdb_scrubber_issues_total",
    dimensions: [
        ("index", "user_by_email"),
        ("type", "dangling_entry"),
        ("phase", "phase1")
    ]
)
counter.increment()

// å‹•çš„ãƒ©ãƒ™ãƒ«ã®è¿½åŠ 
skipCounter.increment(
    by: 1,
    dimensions: [
        ("reason", "tuple_decode_failure"),
        ("phase", "phase1")
    ]
)
```

### åˆæœŸåŒ–

```swift
import Metrics

public actor OnlineIndexScrubber<Record: Sendable> {
    // === Metrics ===
    private let scanProgressCounter: Counter
    private let issuesCounter: Counter
    private let skipCounter: Counter
    private let retryCounter: Counter
    private let progressGauge: Gauge
    private let scanDuration: Timer
    private let batchSizeRecorder: Recorder

    // Common labels
    private let metricsLabels: [(String, String)]

    public init(
        database: any DatabaseProtocol,
        subspace: Subspace,
        metaData: RecordMetaData,
        index: Index,
        recordAccess: any RecordAccess<Record>,
        configuration: ScrubberConfiguration = .default
    ) {
        self.database = database
        self.subspace = subspace
        self.metaData = metaData
        self.index = index
        self.recordAccess = recordAccess
        self.configuration = configuration

        // ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ãƒ©ãƒ™ãƒ«ï¼ˆã™ã¹ã¦ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã«å…±é€šï¼‰
        self.metricsLabels = [
            ("index", index.name),
            ("index_type", index.type.rawValue)
        ]

        // ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®åˆæœŸåŒ–
        // âš ï¸ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¯Sendableã§ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ãªã®ã§ã€actorã§å®‰å…¨ã«ä½¿ç”¨å¯èƒ½
        self.scanProgressCounter = Counter(
            label: "fdb_scrubber_entries_scanned_total",
            dimensions: metricsLabels
        )

        self.issuesCounter = Counter(
            label: "fdb_scrubber_issues_total",
            dimensions: metricsLabels
        )

        self.skipCounter = Counter(
            label: "fdb_scrubber_skipped_total",
            dimensions: metricsLabels
        )

        self.retryCounter = Counter(
            label: "fdb_scrubber_retries_total",
            dimensions: metricsLabels
        )

        // Gaugeã¯é€²æ—ç‡ï¼ˆ0.0ã€œ1.0ï¼‰ã‚’è¨˜éŒ²
        self.progressGauge = Gauge(
            label: "fdb_scrubber_progress_ratio",
            dimensions: metricsLabels
        )

        self.scanDuration = Timer(
            label: "fdb_scrubber_scan_duration_seconds",
            dimensions: metricsLabels
        )

        self.batchSizeRecorder = Recorder(
            label: "fdb_scrubber_batch_size",
            dimensions: metricsLabels,
            aggregate: true
        )
    }
}
```

### ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²ã®å®Ÿè£…ä¾‹ï¼ˆãƒãƒƒãƒåŒ–ï¼‰

```swift
// === Phase 1: scrubIndexEntriesBatch å†… ===

var batchCount = 0
var skipCount = 0

for try await (indexKey, _) in sequence {
    batchCount += 1

    // Tuple decode
    let indexTuple: Tuple
    do {
        indexTuple = try indexSubspace.unpack(indexKey)
    } catch {
        skipCount += 1

        // ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: 1/100ã®ã¿ãƒ­ã‚°å‡ºåŠ›
        if Int.random(in: 0..<100) == 0 {
            logger.warning("Tuple decode failed", metadata: [
                "key": "\(indexKey.safeLogRepresentation)",
                "error": "\(error.safeDescription)"
            ])
        }

        continue
    }

    // ... ä»–ã®å‡¦ç† ...
}

// âœ… ãƒãƒƒãƒçµ‚äº†æ™‚ã«ä¸€æ‹¬è¨˜éŒ²ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šï¼‰
scanProgressCounter.increment(by: batchCount)
if skipCount > 0 {
    skipCounter.increment(
        by: skipCount,
        dimensions: [("reason", "tuple_decode_failure"), ("phase", "phase1")]
    )
}
batchSizeRecorder.record(batchCount)
```

### Prometheusã‚¯ã‚¨ãƒªä¾‹

```promql
# ã‚¹ã‚­ãƒ£ãƒ³é€Ÿåº¦ï¼ˆã‚¨ãƒ³ãƒˆãƒª/ç§’ï¼‰
rate(fdb_scrubber_entries_scanned_total{index="user_by_email"}[1m])

# Issueæ¤œå‡ºç‡ï¼ˆä»¶/ç§’ï¼‰
rate(fdb_scrubber_issues_total{index="user_by_email",type="dangling_entry"}[5m])

# é€²æ—ç‡ï¼ˆ%ï¼‰
fdb_scrubber_progress_ratio{index="user_by_email"} * 100

# æ®‹ã‚Šæ™‚é–“ã®æ¨å®šï¼ˆç§’ï¼‰
(1 - fdb_scrubber_progress_ratio{index="user_by_email"}) /
  rate(fdb_scrubber_progress_ratio{index="user_by_email"}[5m])

# ã‚¹ã‚­ãƒƒãƒ—ç†ç”±ã®å†…è¨³
sum by (reason) (fdb_scrubber_skipped_total{index="user_by_email"})

# ãƒªãƒˆãƒ©ã‚¤é »åº¦ï¼ˆPhase 1ã®ã¿ï¼‰
rate(fdb_scrubber_retries_total{index="user_by_email",phase="phase1"}[5m])

# ã‚¹ã‚­ãƒ£ãƒ³æ™‚é–“ï¼ˆP95ï¼‰
histogram_quantile(0.95, rate(fdb_scrubber_scan_duration_seconds_bucket[5m]))

# ãƒãƒƒãƒã‚µã‚¤ã‚ºã®ä¸­å¤®å€¤
histogram_quantile(0.5, rate(fdb_scrubber_batch_size_bucket[5m]))
```

### Grafanaãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­å®š

```json
{
  "dashboard": {
    "title": "FoundationDB Index Scrubber",
    "panels": [
      {
        "title": "Scan Progress (%)",
        "targets": [
          {
            "expr": "fdb_scrubber_progress_ratio * 100"
          }
        ]
      },
      {
        "title": "Scan Speed (entries/sec)",
        "targets": [
          {
            "expr": "rate(fdb_scrubber_entries_scanned_total[1m])"
          }
        ]
      },
      {
        "title": "Issues Detected",
        "targets": [
          {
            "expr": "sum by (type) (fdb_scrubber_issues_total)"
          }
        ]
      },
      {
        "title": "Skip Reasons",
        "targets": [
          {
            "expr": "sum by (reason) (fdb_scrubber_skipped_total)"
          }
        ]
      },
      {
        "title": "Retry Rate",
        "targets": [
          {
            "expr": "rate(fdb_scrubber_retries_total[5m])"
          }
        ]
      },
      {
        "title": "Estimated Time Remaining",
        "targets": [
          {
            "expr": "(1 - fdb_scrubber_progress_ratio) / rate(fdb_scrubber_progress_ratio[5m])"
          }
        ]
      }
    ]
  }
}
```

---

## RangeSetçµ±åˆ

OnlineIndexScrubberã¯`RangeSet`ã‚’ä½¿ç”¨ã—ã¦é€²è¡ŒçŠ¶æ³ã‚’è¿½è·¡ã—ã€ä¸­æ–­ãƒ»å†é–‹æ™‚ã‚‚æ­£ç¢ºãªçŠ¶æ…‹ã‚’ç¶­æŒã—ã¾ã™ã€‚

### RangeSetã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®é€£æº

```swift
public actor OnlineIndexScrubber<Record: Sendable> {
    private let progressGauge: Gauge

    private func updateProgress(rangeSet: RangeSet) async throws {
        // RangeSetã‹ã‚‰é€²æ—ç‡ã‚’å–å¾—ï¼ˆ0.0 ã€œ 1.0ï¼‰
        let progress = try await rangeSet.getProgress()

        // Gaugeã«è¨˜éŒ²
        progressGauge.record(progress)

        logger.info("Progress updated", metadata: [
            "progress": "\(Int(progress * 100))%"
        ])
    }

    public func scrubIndex() async throws -> ScrubberResult {
        let startTime = Date()

        // RangeSetã®åˆæœŸåŒ–
        let rangeSet = try await initializeRangeSet()

        // åˆæœŸé€²æ—ç‡ã‚’è¨˜éŒ²
        try await updateProgress(rangeSet: rangeSet)

        // Phase 1
        var continuation: FDB.Bytes? = nil
        while true {
            let (nextContinuation, issues, endKey, scanned) = try await scrubIndexEntriesBatch(
                start: continuation,
                rangeSet: rangeSet
            )

            // ãƒãƒƒãƒå®Œäº†å¾Œã€é€²æ—ç‡ã‚’æ›´æ–°
            try await updateProgress(rangeSet: rangeSet)

            guard let next = nextContinuation else {
                break
            }
            continuation = next
        }

        // å®Œäº†æ™‚ã¯é€²æ—ç‡ 1.0
        progressGauge.record(1.0)

        // ...
    }
}
```

### ä¸­æ–­ãƒ»å†é–‹æ™‚ã®å‹•ä½œ

```swift
// åˆå›å®Ÿè¡Œ
let scrubber1 = OnlineIndexScrubber(...)
try await scrubber1.scrubIndex()
// â†’ progressGauge: 0.0 â†’ 0.25 â†’ 0.50 â†’ (ã‚¯ãƒ©ãƒƒã‚·ãƒ¥)

// å†é–‹
let scrubber2 = OnlineIndexScrubber(...)  // åŒã˜subspace/index
try await scrubber2.scrubIndex()
// â†’ RangeSetã‹ã‚‰å‰å›ã®é€²æ—ã‚’å¾©å…ƒ
// â†’ progressGauge: 0.50 â†’ 0.75 â†’ 1.0
```

**é‡è¦**: ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¯ãƒ—ãƒ­ã‚»ã‚¹å†èµ·å‹•æ™‚ã«ãƒªã‚»ãƒƒãƒˆã•ã‚Œã¾ã™ãŒã€RangeSetã¯FoundationDBã«æ°¸ç¶šåŒ–ã•ã‚Œã‚‹ãŸã‚ã€é€²æ—ç‡ã¯æ­£ç¢ºã«å¾©å…ƒã•ã‚Œã¾ã™ã€‚

### Prometheusã§ã®é€²æ—ç›£è¦–

```promql
# ç¾åœ¨ã®é€²æ—ç‡ï¼ˆ%ï¼‰
fdb_scrubber_progress_ratio{index="user_by_email"} * 100

# é€²æ—é€Ÿåº¦ï¼ˆ%/åˆ†ï¼‰
rate(fdb_scrubber_progress_ratio{index="user_by_email"}[1m]) * 60 * 100

# æ®‹ã‚Šæ™‚é–“ã®æ¨å®šï¼ˆåˆ†ï¼‰
(1 - fdb_scrubber_progress_ratio{index="user_by_email"}) /
  rate(fdb_scrubber_progress_ratio{index="user_by_email"}[5m]) / 60
```

---

## ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æˆ¦ç•¥

### ã‚¨ãƒ©ãƒ¼åˆ†é¡

OnlineIndexScrubberã¯ä»¥ä¸‹ã®ç¨®é¡ã®ã‚¨ãƒ©ãƒ¼ã‚’åŒºåˆ¥ã—ã¾ã™ï¼š

| ã‚¨ãƒ©ãƒ¼ç¨®é¡ | å¯¾å‡¦æ–¹æ³• | ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ |
|-----------|---------|-------------------|
| Tuple decodeå¤±æ•— | ã‚¹ã‚­ãƒƒãƒ— + è­¦å‘Šãƒ­ã‚°ï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰ + ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§èª¿æŸ» |
| Deserializationå¤±æ•— | ã‚¹ã‚­ãƒƒãƒ— + è­¦å‘Šãƒ­ã‚°ï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰ + ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | ã‚¹ã‚­ãƒ¼ãƒäº’æ›æ€§ç¢ºèª |
| Dangling entry | allowRepair=trueã§ä¿®å¾© | åŸå› èª¿æŸ»ï¼ˆå‰Šé™¤æ¼ã‚Œï¼Ÿï¼‰ |
| Missing entry | allowRepair=trueã§ä¿®å¾© | åŸå› èª¿æŸ»ï¼ˆæ›¸ãè¾¼ã¿æ¼ã‚Œï¼Ÿï¼‰ |
| Transaction too large | ã‚­ãƒ¼ã‚¹ã‚­ãƒƒãƒ— + é€²æ—è¨˜éŒ² | maxTransactionBytesèª¿æ•´ |
| Retryable FDB error | æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã§ãƒªãƒˆãƒ©ã‚¤ | ã‚¯ãƒ©ã‚¹ã‚¿å¥å…¨æ€§ç¢ºèª |
| Non-retryable error | å³åº§ã«å¤±æ•— | ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¾“ã† |
| Retry exhausted | ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä»˜ãã‚¨ãƒ©ãƒ¼ | è¨­å®šèª¿æ•´ã¾ãŸã¯ã‚¯ãƒ©ã‚¹ã‚¿ç¢ºèª |

### RecordLayerErroræ‹¡å¼µ

```swift
extension RecordLayerError {
    /// ã‚¹ã‚¯ãƒ©ãƒãƒ¼ã®ãƒªãƒˆãƒ©ã‚¤ãŒä¸Šé™ã«é”ã—ãŸ
    ///
    /// - Parameters:
    ///   - phase: å¤±æ•—ã—ãŸãƒ•ã‚§ãƒ¼ã‚ºï¼ˆ"Phase 1", "Phase 2"ï¼‰
    ///   - operation: å¤±æ•—ã—ãŸæ“ä½œï¼ˆ"scrubIndexEntriesBatch", "scrubRecordsBatch"ï¼‰
    ///   - keyRange: å‡¦ç†ä¸­ã®ã‚­ãƒ¼ç¯„å›²
    ///   - attempts: è©¦è¡Œå›æ•°
    ///   - lastError: æœ€å¾Œã®ã‚¨ãƒ©ãƒ¼
    ///   - recommendation: æ¨å¥¨ã•ã‚Œã‚‹å¯¾å‡¦æ–¹æ³•
    public static func scrubberRetryExhausted(
        phase: String,
        operation: String,
        keyRange: String,
        attempts: Int,
        lastError: Error,
        recommendation: String
    ) -> RecordLayerError {
        let message = """
            âŒ Scrubber retry exhausted during \(phase)

            ğŸ“ Operation: \(operation)
            ğŸ“ Key Range: \(keyRange)
            ğŸ“ Attempts: \(attempts)
            ğŸ“ Last Error: \(lastError)

            ğŸ’¡ Recommendation:
            \(recommendation)
            """
        return .internalError(message)
    }

    /// ã‚­ãƒ¼ã‚¹ã‚­ãƒƒãƒ—å‡¦ç†ãŒå¤±æ•—ã—ãŸ
    ///
    /// - Parameters:
    ///   - key: ã‚¹ã‚­ãƒƒãƒ—ã—ã‚ˆã†ã¨ã—ãŸã‚­ãƒ¼
    ///   - reason: å¤±æ•—ç†ç”±
    ///   - attempts: è©¦è¡Œå›æ•°
    public static func scrubberSkipFailed(
        key: String,
        reason: Error,
        attempts: Int
    ) -> RecordLayerError {
        let message = """
            âŒ Failed to skip problematic key after \(attempts) attempts

            ğŸ“ Key: \(key)
            ğŸ“ Reason: \(reason)

            ğŸ’¡ Recommendation:
            This key is blocking progress. Consider:
            1. Increase 'maxRetries' in ScrubberConfiguration
            2. Manually inspect and remove this key
            3. Check FoundationDB cluster health

            âš ï¸  The scrubber cannot proceed past this key until it is resolved.
            """
        return .internalError(message)
    }
}
```

### ã‚¨ãƒ©ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ä»˜ä¸

```swift
// ãƒªãƒˆãƒ©ã‚¤å¤±æ•—æ™‚
if retryCount > configuration.maxRetries {
    let recommendation: String
    if error.code == 2101 { // transaction_too_large
        recommendation = """
            Increase 'maxTransactionBytes' in ScrubberConfiguration.
            Current: \(configuration.maxTransactionBytes) bytes
            Suggested: \(configuration.maxTransactionBytes * 2) bytes

            Or reduce 'entriesScanLimit':
            Current: \(configuration.entriesScanLimit)
            Suggested: \(configuration.entriesScanLimit / 2)
            """
    } else if error.code == 1007 { // transaction_too_old
        recommendation = """
            The transaction took longer than 5 seconds (FoundationDB limit).

            Options:
            1. Reduce 'entriesScanLimit' (current: \(configuration.entriesScanLimit))
            2. Increase 'transactionTimeoutMillis' if cluster allows
            3. Check FoundationDB cluster load
            """
    } else {
        recommendation = """
            Check FoundationDB cluster health.
            Consider increasing 'maxRetries' (current: \(configuration.maxRetries))

            Error code: \(error.code)
            Error description: \(error.localizedDescription)
            """
    }

    throw RecordLayerError.scrubberRetryExhausted(
        phase: "Phase 1 (Index Entries Scan)",
        operation: "scrubIndexEntriesBatch",
        keyRange: "\(currentKey.safeLogRepresentation) to \(endKey?.safeLogRepresentation ?? "end")",
        attempts: retryCount,
        lastError: error,
        recommendation: recommendation
    )
}
```

---

## ãƒ­ã‚°æˆ¦ç•¥

### ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã®ä½¿ã„åˆ†ã‘

| ãƒ¬ãƒ™ãƒ« | ç”¨é€” | ä¾‹ |
|--------|------|-----|
| debug | è©³ç´°ãªãƒ‡ãƒãƒƒã‚°æƒ…å ± | ãƒãƒƒãƒå‡¦ç†ã®é–‹å§‹/çµ‚äº† |
| info | æ­£å¸¸ãªé€²æ—æƒ…å ± | Phaseé–‹å§‹/å®Œäº†ã€çµ±è¨ˆã‚µãƒãƒª |
| warning | ãƒªã‚«ãƒãƒªãƒ¼å¯èƒ½ãªå•é¡Œï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¨å¥¨ï¼‰ | ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå¤±æ•—ã€ãƒªãƒˆãƒ©ã‚¤ |
| error | è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ | ãƒªãƒˆãƒ©ã‚¤ä¸Šé™åˆ°é”ã€å‡¦ç†ä¸­æ–­ |

### ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æˆ¦ç•¥

å¤§é‡ã®warningãƒ­ã‚°ã¯I/Oãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ãªã‚‹ãŸã‚ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã¾ã™ï¼š

```swift
// ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‡: 1/100
private let warningSamplingRate = 100

// Tuple decodeå¤±æ•—
do {
    indexTuple = try indexSubspace.unpack(indexKey)
} catch {
    // âœ… ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¯å…¨ä»¶è¨˜éŒ²
    skipCounter.increment(
        by: 1,
        dimensions: [("reason", "tuple_decode_failure"), ("phase", "phase1")]
    )

    // âœ… ãƒ­ã‚°ã¯1/100ã®ã¿å‡ºåŠ›ï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰
    if Int.random(in: 0..<warningSamplingRate) == 0 {
        logger.warning("Tuple decode failed - skipping entry", metadata: [
            "key": "\(indexKey.safeLogRepresentation)",
            "error": "\(error.safeDescription)",
            "phase": "phase1",
            "note": "This is a sampled log (1/\(warningSamplingRate))"
        ])
    }

    continue
}
```

**ã¾ãŸã¯ã€ãƒãƒƒãƒé›†ç´„**:

```swift
var batchSkipCount = 0

for entry in batch {
    do {
        // ...
    } catch {
        batchSkipCount += 1
        continue
    }
}

// ãƒãƒƒãƒçµ‚äº†æ™‚ã«1å›ã ã‘ãƒ­ã‚°
if batchSkipCount > 0 {
    logger.warning("Skipped entries in batch", metadata: [
        "count": "\(batchSkipCount)",
        "batchSize": "\(batch.count)",
        "reason": "tuple_decode_failure"
    ])
}
```

### ãƒ­ã‚°å‡ºåŠ›ä¾‹

```swift
// === Phaseé–‹å§‹ ===
logger.info("Starting Phase 1: Index entries scan", metadata: [
    "index": "\(index.name)",
    "indexType": "\(index.type.rawValue)",
    "allowRepair": "\(configuration.allowRepair)"
])

// === Tuple decodeå¤±æ•—ï¼ˆwarningã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰ ===
if Int.random(in: 0..<100) == 0 {
    logger.warning("Tuple decode failed - skipping entry", metadata: [
        "key": "\(indexKey.safeLogRepresentation)",
        "error": "\(error.safeDescription)",
        "phase": "phase1",
        "sampling": "1/100"
    ])
}

// === ãƒªãƒˆãƒ©ã‚¤ï¼ˆwarningï¼‰ ===
logger.warning("Retryable error - backing off", metadata: [
    "error": "\(error)",
    "errorCode": "\(error.code)",
    "attempt": "\(retryCount)/\(configuration.maxRetries)",
    "backoffMs": "\(delay)",
    "note": delay > 10000 ? "Long backoff - expected with exponential backoff" : ""
])

// === ãƒªãƒˆãƒ©ã‚¤ä¸Šé™åˆ°é”ï¼ˆerrorï¼‰ ===
logger.error("Retry limit exceeded", metadata: [
    "phase": "Phase 1",
    "operation": "scrubIndexEntriesBatch",
    "attempts": "\(retryCount)",
    "maxRetries": "\(configuration.maxRetries)",
    "lastError": "\(error)",
    "keyRange": "\(currentKey.safeLogRepresentation) to \(endKey?.safeLogRepresentation ?? "end")"
])

// === Phaseå®Œäº†ï¼ˆinfoï¼‰ ===
logger.info("Phase 1 completed", metadata: [
    "entriesScanned": "\(indexEntriesScanned)",
    "issuesDetected": "\(phase1Issues.count)",
    "timeElapsed": "\(String(format: "%.2f", elapsed))s"
])
```

### ã‚­ãƒ¼ã®ã‚µãƒ‹ã‚¿ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³

```swift
import Crypto

extension FDB.Bytes {
    /// ãƒ­ã‚°å‡ºåŠ›ç”¨ã®å®‰å…¨ãªè¡¨ç¾
    ///
    /// å…ˆé ­8ãƒã‚¤ãƒˆã¨SHA256ãƒãƒƒã‚·ãƒ¥ã®ã¿ã‚’è¡¨ç¤ºã—ã€ä¸­é–“éƒ¨åˆ†ã¯éš è”½ã—ã¾ã™ã€‚
    var safeLogRepresentation: String {
        guard !self.isEmpty else { return "<empty>" }

        // å…ˆé ­8ãƒã‚¤ãƒˆ
        let prefix = self.prefix(8).map { String(format: "%02X", $0) }.joined(separator: " ")

        // SHA256ãƒãƒƒã‚·ãƒ¥ã®å…ˆé ­8ãƒã‚¤ãƒˆ
        let hash = SHA256.hash(data: Data(self))
        let hashHex = hash.prefix(8).map { String(format: "%02X", $0) }.joined(separator: " ")

        return "\(prefix)...<hash:\(hashHex)> (length:\(self.count))"
    }
}

extension Error {
    /// ãƒ­ã‚°å‡ºåŠ›ç”¨ã®å®‰å…¨ãªèª¬æ˜
    ///
    /// ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‘ã‚¹ã‚„æ©Ÿå¯†æƒ…å ±ã‚’é™¤å»ã—ã¾ã™ã€‚
    var safeDescription: String {
        let desc = String(describing: self)
        return desc
            .replacingOccurrences(
                of: #"/Users/[^/]+/"#,
                with: "/Users/<redacted>/",
                options: .regularExpression
            )
            .replacingOccurrences(
                of: #"/home/[^/]+/"#,
                with: "/home/<redacted>/",
                options: .regularExpression
            )
    }
}
```

---

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è€ƒæ…®äº‹é …

### ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²ã®æœ€é©åŒ–

#### âŒ éåŠ¹ç‡: ã‚¨ãƒ³ãƒˆãƒªã”ã¨ã«è¨˜éŒ²

```swift
for try await (indexKey, _) in sequence {
    scanProgressCounter.increment(by: 1)  // 100ä¸‡ã‚¨ãƒ³ãƒˆãƒªãªã‚‰100ä¸‡å›å‘¼ã³å‡ºã—
    // ...
}
```

**å•é¡Œ**:
- é–¢æ•°å‘¼ã³å‡ºã—ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰
- ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã¸ã®é »ç¹ãªã‚¢ã‚¯ã‚»ã‚¹

#### âœ… åŠ¹ç‡çš„: ãƒãƒƒãƒã”ã¨ã«è¨˜éŒ²

```swift
var batchCount = 0

for try await (indexKey, _) in sequence {
    batchCount += 1
    // ...
}

// ãƒãƒƒãƒçµ‚äº†æ™‚ã«ä¸€æ‹¬è¨˜éŒ²
scanProgressCounter.increment(by: batchCount)
```

**åŠ¹æœ**:
- å‘¼ã³å‡ºã—å›æ•°ãŒ1/1000ã«å‰Šæ¸›ï¼ˆentriesScanLimit=1000ã®å ´åˆï¼‰
- CPUä½¿ç”¨ç‡ãŒç´„5ã€œ10%å‰Šæ¸›

### ãƒ­ã‚°ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°

#### âŒ éåŠ¹ç‡: å…¨ä»¶ãƒ­ã‚°å‡ºåŠ›

```swift
for entry in batch {
    do {
        // ...
    } catch {
        logger.warning("Failed", metadata: [...])  // å¤§é‡ã®I/O
    }
}
```

**å•é¡Œ**:
- ãƒ‡ã‚£ã‚¹ã‚¯I/Oãƒœãƒˆãƒ«ãƒãƒƒã‚¯
- ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®è‚¥å¤§åŒ–

#### âœ… åŠ¹ç‡çš„: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°

```swift
for entry in batch {
    do {
        // ...
    } catch {
        // ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¯å…¨ä»¶è¨˜éŒ²
        skipCounter.increment(by: 1, dimensions: [("reason", "failure")])

        // ãƒ­ã‚°ã¯1/100ã®ã¿
        if Int.random(in: 0..<100) == 0 {
            logger.warning("Failed", metadata: [...])
        }
    }
}
```

**åŠ¹æœ**:
- ãƒ­ã‚°I/OãŒ1/100ã«å‰Šæ¸›
- ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡ãŒå¤§å¹…ã«å‰Šæ¸›
- ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¯å…¨ä»¶è¨˜éŒ²ã•ã‚Œã‚‹ãŸã‚ã€çµ±è¨ˆã«å½±éŸ¿ãªã—

### åŒæ™‚å®Ÿè¡Œæ€§ã¨ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ãƒ†ã‚£

#### swift-metricsã®ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•æ€§

swift-metricsã®å…¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹å‹ã¯**Sendableãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«æº–æ‹ **ã—ã¦ãŠã‚Šã€**å†…éƒ¨çš„ã«ãƒ­ãƒƒã‚¯ã§ä¿è­·**ã•ã‚Œã¦ã„ã¾ã™ã€‚

```swift
// âœ… å®‰å…¨: è¤‡æ•°ã®ã‚¿ã‚¹ã‚¯ã‹ã‚‰ä¸¦è¡Œã«å‘¼ã³å‡ºã—å¯èƒ½
Task {
    counter.increment()
}
Task {
    counter.increment()
}
// â†’ ç«¶åˆãªã—ã€æ­£ã—ãã‚«ã‚¦ãƒ³ãƒˆ
```

#### OnlineIndexScrubberã®actoråŒ–

```swift
// âœ… æ¨å¥¨: actorã‚’ä½¿ç”¨
public actor OnlineIndexScrubber<Record: Sendable> {
    private let scanProgressCounter: Counter  // Sendableãªã®ã§å®‰å…¨

    public func scrubIndex() async throws -> ScrubberResult {
        // actorãŒåŒæ™‚å®Ÿè¡Œã‚’åˆ¶å¾¡
        scanProgressCounter.increment(by: 100)  // ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•
    }
}
```

**ç†ç”±**:
- actorãŒãƒ¡ã‚½ãƒƒãƒ‰ã®æ’ä»–åˆ¶å¾¡ã‚’ä¿è¨¼
- ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¯Sendableãªã®ã§ã€actorå¢ƒç•Œã‚’è¶Šãˆã¦å®‰å…¨ã«ä½¿ç”¨å¯èƒ½
- æ˜ç¤ºçš„ãªãƒ­ãƒƒã‚¯ï¼ˆNSLockç­‰ï¼‰ã¯ä¸è¦

### ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æœ€é©åŒ–

#### RangeSetã®ãƒ¡ãƒ¢ãƒªåŠ¹ç‡

RangeSetã¯FoundationDBã«æ°¸ç¶šåŒ–ã•ã‚Œã‚‹ãŸã‚ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã¯æœ€å°é™ã§ã™ï¼š

```swift
// ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: O(1)ï¼ˆç¾åœ¨ã®ãƒãƒƒãƒã®ã¿ï¼‰
let rangeSet = try await initializeRangeSet()

// é€²æ—ã‚’ã‚¯ã‚¨ãƒªã—ã¦ã‚‚ã€å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ãªã„
let progress = try await rangeSet.getProgress()  // è»½é‡
```

#### ãƒãƒƒãƒã‚µã‚¤ã‚ºã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

```swift
// å°ã•ã™ãã‚‹: ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãŒå¤§ãã„
let config = ScrubberConfiguration(
    entriesScanLimit: 10  // âŒ é »ç¹ãªãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³
)

// å¤§ãã™ãã‚‹: ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
let config = ScrubberConfiguration(
    entriesScanLimit: 100_000  // âŒ transaction_too_old
)

// âœ… æ¨å¥¨: 1000ã€œ10000
let config = ScrubberConfiguration(
    entriesScanLimit: 1000  // ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„
)
```

---

## é‹ç”¨ã‚¬ã‚¤ãƒ‰

### æ¨å¥¨è¨­å®š

#### æœ¬ç•ªç’°å¢ƒ

```swift
let productionConfig = ScrubberConfiguration(
    entriesScanLimit: 1_000,
    maxTransactionBytes: 5_000_000,
    transactionTimeoutMillis: 4_000,
    readYourWrites: false,
    allowRepair: false,  // âš ï¸ æœ€åˆã¯falseã§å®Ÿè¡Œã—ã€å•é¡Œã‚’ç¢ºèª
    supportedTypes: [.value],
    logWarningsLimit: 100,
    maxRetries: 20,
    retryDelayMillis: 100
)
```

#### é–‹ç™ºç’°å¢ƒ

```swift
let devConfig = ScrubberConfiguration(
    entriesScanLimit: 100,
    maxTransactionBytes: 1_000_000,
    transactionTimeoutMillis: 2_000,
    readYourWrites: false,
    allowRepair: true,  // é–‹ç™ºç’°å¢ƒã§ã¯è‡ªå‹•ä¿®å¾©
    supportedTypes: [.value],
    logWarningsLimit: 10,
    maxRetries: 5,
    retryDelayMillis: 50
)
```

### ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«ï¼ˆPrometheusï¼‰

```yaml
groups:
  - name: fdb_scrubber
    interval: 1m
    rules:
      # é«˜ã„Issueæ¤œå‡ºç‡
      - alert: HighScrubberIssueRate
        expr: rate(fdb_scrubber_issues_total[5m]) > 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High scrubber issue detection rate for {{ $labels.index }}"
          description: "{{ $value }} issues/sec detected"

      # ã‚¹ã‚­ãƒƒãƒ—ãŒå¤šã„
      - alert: HighScrubberSkipRate
        expr: rate(fdb_scrubber_skipped_total[5m]) > 5
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High scrubber skip rate for {{ $labels.index }}"
          description: "{{ $value }} skips/sec - check data integrity"

      # ãƒªãƒˆãƒ©ã‚¤ãŒé »ç™º
      - alert: FrequentScrubberRetries
        expr: rate(fdb_scrubber_retries_total[5m]) > 1
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Frequent retries for {{ $labels.index }}"
          description: "{{ $value }} retries/sec - check cluster health"

      # ã‚¹ã‚¯ãƒ©ãƒãƒ¼ãŒåœæ»
      - alert: ScrubberStalled
        expr: rate(fdb_scrubber_progress_ratio[10m]) == 0
        for: 30m
        labels:
          severity: critical
        annotations:
          summary: "Scrubber stalled for {{ $labels.index }}"
          description: "No progress in 30 minutes"

      # ã‚¹ã‚­ãƒ£ãƒ³æ™‚é–“ãŒé•·ã„
      - alert: SlowScrubberScan
        expr: histogram_quantile(0.95, rate(fdb_scrubber_scan_duration_seconds_bucket[5m])) > 300
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Slow scrubber scan for {{ $labels.index }}"
          description: "P95 scan time: {{ $value }}s"
```

### å®šæœŸå®Ÿè¡Œ

```swift
import Foundation

/// ã‚¹ã‚¯ãƒ©ãƒãƒ¼ã®å®šæœŸå®Ÿè¡Œ
actor ScrubberScheduler {
    private let interval: TimeInterval
    private var task: Task<Void, Never>?

    init(interval: TimeInterval = 3600) {  // 1æ™‚é–“ã”ã¨
        self.interval = interval
    }

    func start() {
        task = Task {
            while !Task.isCancelled {
                do {
                    let result = try await runScrubber()

                    if !result.isHealthy {
                        logger.warning("Index health issues detected", metadata: [
                            "issuesDetected": "\(result.summary.issuesDetected)"
                        ])
                        // ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡
                    }

                    try await Task.sleep(nanoseconds: UInt64(interval * 1_000_000_000))
                } catch {
                    logger.error("Scrubber execution failed", metadata: [
                        "error": "\(error)"
                    ])

                    // ã‚¨ãƒ©ãƒ¼æ™‚ã¯çŸ­ã„é–“éš”ã§ãƒªãƒˆãƒ©ã‚¤
                    try? await Task.sleep(nanoseconds: 300_000_000_000)  // 5åˆ†
                }
            }
        }
    }

    func stop() {
        task?.cancel()
        task = nil
    }

    private func runScrubber() async throws -> ScrubberResult {
        let scrubber = OnlineIndexScrubber<User>(
            database: database,
            subspace: subspace,
            metaData: metaData,
            index: emailIndex,
            recordAccess: UserAccess()
        )

        return try await scrubber.scrubIndex()
    }
}

// ä½¿ç”¨ä¾‹
let scheduler = ScrubberScheduler(interval: 3600)
await scheduler.start()

// ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†æ™‚
await scheduler.stop()
```

---

## å®Ÿè£…ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

### å®Œå…¨ãªå®Ÿè£…ä¾‹

```swift
import Foundation
import FoundationDB
import Logging
import Metrics

public actor OnlineIndexScrubber<Record: Sendable> {
    // === Core Properties ===
    private let database: any DatabaseProtocol
    private let subspace: Subspace
    private let metaData: RecordMetaData
    private let index: Index
    private let recordAccess: any RecordAccess<Record>
    private let configuration: ScrubberConfiguration
    private let logger: Logger

    // === Metrics ===
    // âš ï¸ swift-metricsã¯Sendableã§ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ãªã®ã§ã€actorã§å®‰å…¨ã«ä½¿ç”¨å¯èƒ½
    private let scanProgressCounter: Counter
    private let issuesCounter: Counter
    private let skipCounter: Counter
    private let retryCounter: Counter
    private let progressGauge: Gauge
    private let scanDuration: Timer
    private let batchSizeRecorder: Recorder
    private let metricsLabels: [(String, String)]

    // === Initialization ===
    public init(
        database: any DatabaseProtocol,
        subspace: Subspace,
        metaData: RecordMetaData,
        index: Index,
        recordAccess: any RecordAccess<Record>,
        configuration: ScrubberConfiguration = .default
    ) {
        self.database = database
        self.subspace = subspace
        self.metaData = metaData
        self.index = index
        self.recordAccess = recordAccess
        self.configuration = configuration
        self.logger = Logger(label: "com.fdb.recordlayer.scrubber")

        // Metrics labels
        self.metricsLabels = [
            ("index", index.name),
            ("index_type", index.type.rawValue)
        ]

        // Initialize metrics
        self.scanProgressCounter = Counter(
            label: "fdb_scrubber_entries_scanned_total",
            dimensions: metricsLabels
        )
        self.issuesCounter = Counter(
            label: "fdb_scrubber_issues_total",
            dimensions: metricsLabels
        )
        self.skipCounter = Counter(
            label: "fdb_scrubber_skipped_total",
            dimensions: metricsLabels
        )
        self.retryCounter = Counter(
            label: "fdb_scrubber_retries_total",
            dimensions: metricsLabels
        )
        self.progressGauge = Gauge(
            label: "fdb_scrubber_progress_ratio",
            dimensions: metricsLabels
        )
        self.scanDuration = Timer(
            label: "fdb_scrubber_scan_duration_seconds",
            dimensions: metricsLabels
        )
        self.batchSizeRecorder = Recorder(
            label: "fdb_scrubber_batch_size",
            dimensions: metricsLabels,
            aggregate: true
        )
    }

    // === Public API ===
    public func scrubIndex() async throws -> ScrubberResult {
        let start = Date()

        do {
            logger.info("Starting index scrubber", metadata: [
                "index": "\(index.name)",
                "indexType": "\(index.type.rawValue)",
                "allowRepair": "\(configuration.allowRepair)"
            ])

            // RangeSetã®åˆæœŸåŒ–
            let rangeSet = try await initializeRangeSet()

            // åˆæœŸé€²æ—ç‡ã‚’è¨˜éŒ²
            progressGauge.record(0.0)

            // Phase 1: Index entries scan
            let (phase1Issues, indexEntriesScanned) = try await scrubIndexEntries(
                rangeSet: rangeSet
            )

            logger.info("Phase 1 completed", metadata: [
                "entriesScanned": "\(indexEntriesScanned)",
                "issuesDetected": "\(phase1Issues.count)"
            ])

            // Phase 2: Records scan
            let (phase2Issues, recordsScanned) = try await scrubRecords(
                rangeSet: rangeSet
            )

            logger.info("Phase 2 completed", metadata: [
                "recordsScanned": "\(recordsScanned)",
                "issuesDetected": "\(phase2Issues.count)"
            ])

            // å®Œäº†æ™‚ã¯é€²æ—ç‡ 1.0
            progressGauge.record(1.0)

            // Aggregate results
            let allIssues = phase1Issues + phase2Issues
            let totalIssues = allIssues.count
            let repairedIssues = configuration.allowRepair ? totalIssues : 0

            let elapsed = Date().timeIntervalSince(start)
            scanDuration.recordSeconds(elapsed)

            let result = ScrubberResult(
                isHealthy: totalIssues == 0,
                completedSuccessfully: true,
                summary: ScrubberSummary(
                    timeElapsed: elapsed,
                    entriesScanned: indexEntriesScanned,
                    recordsScanned: recordsScanned,
                    issuesDetected: totalIssues,
                    issuesRepaired: repairedIssues,
                    indexName: index.name
                ),
                terminationReason: nil
            )

            logger.info("Scrubber completed", metadata: [
                "isHealthy": "\(result.isHealthy)",
                "totalIssues": "\(totalIssues)",
                "repairedIssues": "\(repairedIssues)",
                "timeElapsed": "\(String(format: "%.2f", result.summary.timeElapsed))s"
            ])

            return result

        } catch {
            logger.error("Scrubber failed", metadata: [
                "error": "\(error.safeDescription)"
            ])

            // Record failure metric
            issuesCounter.increment(
                by: 1,
                dimensions: [("type", "scrubber_failure"), ("phase", "overall")]
            )

            let elapsed = Date().timeIntervalSince(start)
            let result = ScrubberResult(
                isHealthy: false,
                completedSuccessfully: false,
                summary: ScrubberSummary(
                    timeElapsed: elapsed,
                    entriesScanned: 0,
                    recordsScanned: 0,
                    issuesDetected: 0,
                    issuesRepaired: 0,
                    indexName: index.name
                ),
                terminationReason: "\(error)"
            )

            throw error
        }
    }

    // === Private Implementation ===

    private func scrubIndexEntriesBatch(...) async throws -> (...) {
        var batchCount = 0
        var skipCount = 0
        var issuesFound: [ScrubberIssue] = []

        for try await (indexKey, _) in sequence {
            batchCount += 1

            // Tuple decode with error handling
            let indexTuple: Tuple
            do {
                indexTuple = try indexSubspace.unpack(indexKey)
            } catch {
                skipCount += 1

                // ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: 1/100ã®ã¿ãƒ­ã‚°
                if Int.random(in: 0..<100) == 0 {
                    logger.warning("Tuple decode failed", metadata: [
                        "key": "\(indexKey.safeLogRepresentation)",
                        "error": "\(error.safeDescription)",
                        "sampling": "1/100"
                    ])
                }
                continue
            }

            // ... rest of implementation ...
        }

        // âœ… ãƒãƒƒãƒçµ‚äº†æ™‚ã«ä¸€æ‹¬è¨˜éŒ²
        scanProgressCounter.increment(by: batchCount)
        if skipCount > 0 {
            skipCounter.increment(
                by: skipCount,
                dimensions: [("reason", "tuple_decode_failure"), ("phase", "phase1")]
            )
        }
        batchSizeRecorder.record(batchCount)

        // é€²æ—ç‡ã‚’æ›´æ–°
        let progress = try await rangeSet.getProgress()
        progressGauge.record(progress)

        return (nextContinuation, issuesFound, batchEndKey, batchCount)
    }
}
```

---

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### å•é¡Œ: ã‚¹ã‚­ãƒƒãƒ—ãŒå¤šã„

**ç—‡çŠ¶**: `fdb_scrubber_skipped_total` ãŒé«˜ã„

**åŸå› ã¨å¯¾å‡¦**:

| reason | åŸå›  | å¯¾å‡¦æ–¹æ³• |
|--------|------|---------|
| tuple_decode_failure | ãƒ‡ãƒ¼ã‚¿ç ´æã¾ãŸã¯Subspaceä¸ä¸€è‡´ | 1. Subspaceè¨­å®šã‚’ç¢ºèª<br>2. ãƒ‡ãƒ¼ã‚¿å¾©å…ƒã‚’æ¤œè¨ |
| deserialization_failure | ã‚¹ã‚­ãƒ¼ãƒéäº’æ› | 1. RecordAccessã®å®Ÿè£…ã‚’ç¢ºèª<br>2. ã‚¹ã‚­ãƒ¼ãƒç§»è¡ŒãŒå¿…è¦ã‹æ¤œè¨ |
| transaction_too_large | ãƒãƒƒãƒã‚µã‚¤ã‚ºãŒå¤§ãã™ãã‚‹ | entriesScanLimitã‚’å‰Šæ¸› |

**ãƒ‡ãƒãƒƒã‚°æ‰‹é †**:

```bash
# ã‚¹ã‚­ãƒƒãƒ—ç†ç”±ã®å†…è¨³ã‚’ç¢ºèª
curl -G 'http://prometheus:9090/api/v1/query' \
  --data-urlencode 'query=sum by (reason) (fdb_scrubber_skipped_total{index="user_by_email"})'

# ãƒ­ã‚°ã§è©³ç´°ã‚’ç¢ºèªï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚Œã¦ã„ã‚‹ãŸã‚å…¨ä»¶ã§ã¯ãªã„ï¼‰
grep "skipping" /var/log/scrubber.log | tail -20
```

### å•é¡Œ: ãƒªãƒˆãƒ©ã‚¤ãŒé »ç™º

**ç—‡çŠ¶**: `fdb_scrubber_retries_total` ãŒé«˜ã„

**åŸå› ã¨å¯¾å‡¦**:

| error_code | èª¬æ˜ | å¯¾å‡¦æ–¹æ³• |
|-----------|------|---------|
| 1007 | transaction_too_old (5ç§’è¶…é) | entriesScanLimitã‚’å‰Šæ¸› |
| 2101 | transaction_too_large | maxTransactionBytesã‚’å¢—ã‚„ã™ã‹entriesScanLimitã‚’å‰Šæ¸› |
| 1020 | not_committed (ç«¶åˆ) | ã‚¯ãƒ©ã‚¹ã‚¿è² è·ã‚’ç¢ºèª |

**ãƒ‡ãƒãƒƒã‚°æ‰‹é †**:

```bash
# ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰åˆ¥ã®ãƒªãƒˆãƒ©ã‚¤ç‡
curl -G 'http://prometheus:9090/api/v1/query' \
  --data-urlencode 'query=rate(fdb_scrubber_retries_total[5m])'
```

### å•é¡Œ: ã‚¹ã‚­ãƒ£ãƒ³ãŒé…ã„

**ç—‡çŠ¶**: `fdb_scrubber_scan_duration_seconds` ãŒé•·ã„ï¼ˆ>300ç§’ï¼‰

**åŸå› ã¨å¯¾å‡¦**:

1. **å¤§é‡ã®Issue**: allowRepair=trueã§ä¿®å¾©å‡¦ç†ãŒç™ºç”Ÿ
   - å¯¾å‡¦: å…ˆã«allowRepair=falseã§å®Ÿè¡Œã—ã€Issueã®é‡ã‚’ç¢ºèª
2. **ã‚¯ãƒ©ã‚¹ã‚¿è² è·**: FoundationDBã‚¯ãƒ©ã‚¹ã‚¿ãŒé…ã„
   - å¯¾å‡¦: fdbcliã§ã‚¯ãƒ©ã‚¹ã‚¿çŠ¶æ…‹ã‚’ç¢ºèª
3. **ãƒãƒƒãƒã‚µã‚¤ã‚º**: å°ã•ã™ãã¦ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãŒå¤§ãã„
   - å¯¾å‡¦: entriesScanLimitã‚’å¢—ã‚„ã™ï¼ˆãŸã ã—ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚ºã«æ³¨æ„ï¼‰

**ãƒ‡ãƒãƒƒã‚°æ‰‹é †**:

```bash
# é€²æ—ç‡ã‚’ç¢ºèª
curl -G 'http://prometheus:9090/api/v1/query' \
  --data-urlencode 'query=fdb_scrubber_progress_ratio{index="user_by_email"}'

# é€²æ—é€Ÿåº¦ã‚’ç¢ºèªï¼ˆ%/åˆ†ï¼‰
curl -G 'http://prometheus:9090/api/v1/query' \
  --data-urlencode 'query=rate(fdb_scrubber_progress_ratio{index="user_by_email"}[5m]) * 60 * 100'
```

### å•é¡Œ: ã‚¹ã‚¯ãƒ©ãƒãƒ¼ãŒåœæ»

**ç—‡çŠ¶**: `fdb_scrubber_progress_ratio` ãŒå¤‰åŒ–ã—ãªã„

**åŸå› ã¨å¯¾å‡¦**:

1. **ç‰¹å®šã®ã‚­ãƒ¼ã§å¤±æ•—**: ã‚¹ã‚­ãƒƒãƒ—å‡¦ç†ãŒå¤±æ•—ã—ã¦ã„ã‚‹
   - ãƒ­ã‚°ã§`RecordLayerError.scrubberSkipFailed`ã‚’ç¢ºèª
   - è©²å½“ã‚­ãƒ¼ã‚’æ‰‹å‹•ã§å‰Šé™¤ã¾ãŸã¯ä¿®æ­£

2. **RangeSetã®å•é¡Œ**: é€²æ—è¿½è·¡ãŒæ­£ã—ãæ›´æ–°ã•ã‚Œã¦ã„ãªã„
   - RangeSetã®ãƒ‡ãƒ¼ã‚¿ã‚’fdbcliã§ç¢ºèª

**ãƒ‡ãƒãƒƒã‚°æ‰‹é †**:

```bash
# ã‚¢ãƒ©ãƒ¼ãƒˆãŒç™ºç«ã—ã¦ã„ã‚‹ã‹ç¢ºèª
curl 'http://prometheus:9090/api/v1/alerts' | jq '.data.alerts[] | select(.labels.alertname == "ScrubberStalled")'

# æœ€æ–°ã®ãƒ­ã‚°ã‚’ç¢ºèª
tail -f /var/log/scrubber.log | grep -E "(error|warning)"
```

---

## å‚è€ƒè³‡æ–™

- [swift-metrics on GitHub](https://github.com/apple/swift-metrics)
- [swift-metrics on DeepWiki](https://deepwiki.com/apple/swift-metrics)
- [SwiftPrometheus on GitHub](https://github.com/MrLotU/SwiftPrometheus)
- [swift-log on GitHub](https://github.com/apple/swift-log)
- [Prometheus Documentation](https://prometheus.io/docs/)
- [Grafana Documentation](https://grafana.com/docs/)
- [FoundationDB Documentation](https://apple.github.io/foundationdb/)

---

**Last Updated**: 2025-01-15
**swift-metrics Version**: 2.5.0+
**SwiftPrometheus Version**: 1.0.0+
**Swift Version**: 6.0+
